export {}; // Ensures module context for global declarations

declare global {
  interface Window {
    webkitSpeechRecognition: any;
    SpeechRecognition: any;
  }
}

import React, { useState, useRef, useEffect } from 'react';

interface SpeechToTextInputProps {
  onTextChange: (text: string) => void;
  onStart?: () => void;
  onStop?: () => void;
  initialText?: string;
  placeholder?: string;
  disabled?: boolean;
}

const SpeechToTextInput: React.FC<SpeechToTextInputProps> = ({
  onTextChange,
  onStart,
  onStop,
  initialText = '',
  placeholder = 'Speak or type here...',
  disabled = false
}) => {
  const [isListening, setIsListening] = useState(false);
  const [finalText, setFinalText] = useState(initialText);
  const [interimText, setInterimText] = useState('');
  const recognitionRef = useRef<any>(null);
  const isListeningRef = useRef(isListening);
  const resetFlagRef = useRef(false);

  // Update ref when state changes
  useEffect(() => {
    isListeningRef.current = isListening;
  }, [isListening]);

  // Reset text when initialText is cleared by parent
  useEffect(() => {
    if (initialText === '' && (finalText !== '' || interimText !== '')) {
      setFinalText('');
      setInterimText('');
      resetFlagRef.current = true;
    }
  }, [initialText]);

  useEffect(() => {
    if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognitionRef.current = new SpeechRecognition();
      recognitionRef.current.continuous = true;
      recognitionRef.current.interimResults = true;
      recognitionRef.current.lang = 'en-US';

      recognitionRef.current.onresult = (event: any) => {
        if (resetFlagRef.current) {
          resetFlagRef.current = false;
          return;
        }
        
        let newFinal = '';
        let newInterim = '';
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const result = event.results[i];
          const transcript = result[0].transcript;
          
          if (result.isFinal) {
            // Add space only when needed
            const shouldAddSpace = newFinal.length > 0 && !newFinal.endsWith(' ') && 
                                  !transcript.startsWith(' ');
            newFinal += (shouldAddSpace ? ' ' : '') + transcript;
          } else {
            newInterim += transcript;
          }
        }

        if (newFinal) {
          setFinalText(prev => {
            // Handle concatenation with existing text
            if (!prev) return newFinal;
            const prevText = prev.endsWith(' ') ? prev : prev + ' ';
            return prevText + newFinal;
          });
          setInterimText('');
        }
        
        if (newInterim) {
          setInterimText(newInterim);
        }
      };

      recognitionRef.current.onerror = (event: any) => {
        console.error('Speech recognition error', event.error);
        stopListening();
      };

      recognitionRef.current.onend = () => {
        if (isListeningRef.current) {
          recognitionRef.current.start();
        } else {
          setInterimText('');
        }
      };
    } else {
      console.warn('Web Speech API is not supported in this browser');
    }

    return () => {
      stopListening();
    };
  }, []);

  useEffect(() => {
    onTextChange(finalText + interimText);
  }, [finalText, interimText, onTextChange]);

  const startListening = () => {
    if (disabled) return;
    
    if (recognitionRef.current && !isListening) {
      try {
        resetFlagRef.current = false;
        recognitionRef.current.start();
        setIsListening(true);
        if (onStart) onStart();
      } catch (error) {
        console.error('Speech recognition start error:', error);
      }
    }
  };

  const stopListening = () => {
    if (recognitionRef.current && isListening) {
      recognitionRef.current.stop();
      setIsListening(false);
      setInterimText('');
      if (onStop) onStop();
    }
  };

  const toggleListening = () => {
    if (isListening) {
      stopListening();
    } else {
      startListening();
    }
  };

  const handleTextChange = (e: React.ChangeEvent<HTMLTextAreaElement>) => {
    const newText = e.target.value;
    setFinalText(newText);
    setInterimText('');
    onTextChange(newText);
  };

  const clearText = () => {
    setFinalText('');
    setInterimText('');
    onTextChange('');
  };

  return (
    <div className="w-full">
      <div className="relative">
        <textarea
          value={finalText + interimText}
          onChange={handleTextChange}
          placeholder={placeholder}
          className="w-full p-4 border rounded-lg focus:ring-2 focus:ring-blue-500 focus:border-transparent min-h-[120px]"
          disabled={disabled}
        />
        <div className="absolute right-3 bottom-3 flex gap-2">
          <button
            type="button"
            onClick={clearText}
            disabled={disabled}
            className="p-2 rounded-full bg-gray-200 hover:bg-gray-300 text-gray-700"
            title="Clear text"
          >
            <svg xmlns="http://www.w3.org/2000/svg" className="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
              <path fillRule="evenodd" d="M9 2a1 1 0 00-.894.553L7.382 4H4a1 1 0 000 2v10a2 2 0 002 2h8a2 2 0 002-2V6a1 1 0 100-2h-3.382l-.724-1.447A1 1 0 0011 2H9zM7 8a1 1 0 012 0v6a1 1 0 11-2 0V8zm5-1a1 1 0 00-1 1v6a1 1 0 102 0V8a1 1 0 00-1-1z" clipRule="evenodd" />
            </svg>
          </button>
          <button
            type="button"
            onClick={toggleListening}
            disabled={disabled}
            className={`p-2 rounded-full ${
              isListening 
                ? 'bg-red-500 hover:bg-red-600' 
                : 'bg-blue-500 hover:bg-blue-600'
            } text-white`}
            title={isListening ? "Stop listening" : "Start listening"}
          >
            {isListening ? (
              <svg xmlns="http://www.w3.org/2000/svg" className="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
                <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8 7a1 1 0 00-1 1v4a1 1 0 102 0V8a1 1 0 00-1-1zm4 0a1 1 0 00-1 1v4a1 1 0 102 0V8a1 1 0 00-1-1z" clipRule="evenodd" />
              </svg>
            ) : (
              <svg xmlns="http://www.w3.org/2000/svg" className="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
                <path fillRule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 00-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z" clipRule="evenodd" />
              </svg>
            )}
          </button>
        </div>
      </div>
      {isListening && (
        <div className="mt-2 text-sm text-blue-600 flex items-center">
          <div className="w-3 h-3 rounded-full bg-red-500 animate-pulse mr-2"></div>
          Listening... {interimText && <span className="ml-2 text-gray-500">{interimText}</span>}
        </div>
      )}
    </div>
  );
};

export default SpeechToTextInput;